# -*- coding: utf-8 -*-
"""Core functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yGUus1myQQ72rGxZvQuWRMNkLXDzSrP8
"""

import scanpy as sc
import pandas as pd
import numpy as np
import warnings
import matplotlib.pyplot as plt
from scipy.ndimage import gaussian_filter1d
import scipy.sparse
from sklearn.mixture import GaussianMixture
from sklearn.metrics import precision_recall_fscore_support
from hmmlearn import hmm
from scipy import stats
from scipy.ndimage import uniform_filter1d
from scipy.ndimage import gaussian_filter1d
from scipy import stats
from scipy.signal import medfilt, savgol_filter
import re
import itertools

def find_cluster_references(
    adata: sc.AnnData,
    cluster_key: str = 'leiden_clusters',
    layer: str | None = None,
    n_genes_subset: int = 3000,
    gmm_components: int = 2,
    random_state: int = 42,
    verbose: bool = False
) -> dict[str, list[str]]:
    """
    For each cluster in adata.obs[cluster_key], select a diploid reference
    via low‐variance cells. Returns { cluster: [cell, ...], ... }.
    """
    if cluster_key not in adata.obs:
        raise KeyError(f"{cluster_key!r} not in adata.obs")

    X = adata.layers[layer] if layer else adata.X
    if scipy.sparse.issparse(X):
        X = X.tocsr()

    nonmt = ~adata.var_names.str.upper().str.startswith('MT-')
    avail = np.where(nonmt)[0]
    if len(avail) >= n_genes_subset:
        rng = np.random.RandomState(random_state)
        subset_idx = rng.choice(avail, n_genes_subset, replace=False)
    else:
        subset_idx = avail if len(avail)>0 else np.arange(adata.n_vars)

    refs: dict[str, list[str]] = {}

    clusters = [str(x) for x in adata.obs[cluster_key].unique()]

    for cl in clusters:
        mask_cl = (adata.obs[cluster_key].astype(str).values == cl)
        idx_cl  = np.where(mask_cl)[0]
        if len(idx_cl) < 5:
            if verbose:
                print(f"Cluster {cl!r}: only {len(idx_cl)} cells → skipping")
            refs[cl] = []
            continue

        block = X[idx_cl[:, None], subset_idx]

        if scipy.sparse.issparse(block):
            block = block.toarray()

        vars_ = np.nanvar(block, axis=1, ddof=1).reshape(-1,1)

        gmm = GaussianMixture(n_components=gmm_components,
                              random_state=random_state)
        gmm.fit(vars_)
        lbl = gmm.predict(vars_)
        means = gmm.means_.flatten()
        dip = int(np.argmin(means))

        dip_idx   = idx_cl[lbl == dip]
        dip_cells = adata.obs_names[dip_idx].tolist()
        refs[cl]   = dip_cells

        if verbose:
            print(f"Cluster {cl!r}: {len(dip_cells)}/{len(idx_cl)} refs "
                  f"  (GMM means var={means.round(4)})")

    return refs

def detect_cnas_per_cluster(
    adata,
    cluster_key: str,
    cluster_refs: dict[str, list[str]],
    window_size: int = 100,
    min_genes_per_window: int = 10,
    smoothing_sigma: float = 1.0,
    lfc_threshold: float = 0.1,
    fraction_threshold: float = 0.2,
    layer: str | None = None
) -> tuple[pd.DataFrame, list[dict], pd.DataFrame]:
    """
    For each cluster in adata.obs[cluster_key], uses cluster_refs to compute
    smoothed per-window log2 fold-change and calls gains/losses by requiring
    that at least `fraction_threshold` of windows on a chromosome exceed
    +lfc_threshold (gain) or -lfc_threshold (loss).

    Returns
    -------
    calls_chr : pd.DataFrame
        DataFrame of shape (n_cells, n_chromosomes) with values in {-1, 0, +1}.
    """
    X = adata.layers[layer] if layer else adata.X
    if scipy.sparse.issparse(X):
        X = X.toarray()

    var = adata.var.copy()
    var['chrom'] = var['chromosome'].astype(str)
    var['start'] = pd.to_numeric(var['start'], errors='coerce')
    var = var.dropna(subset=['chrom','start'])
    def chr_key(c):
        c = str(c)
        return (int(c), '') if c.isdigit() else (np.inf, c)
    var['_idx'] = np.arange(var.shape[0])
    var = var.sort_values(['chrom','start'], key=lambda col: col.map(chr_key))
    sorted_idx = var['_idx'].values.astype(int)
    gene_chroms = var['chrom'].values

    Xs = X[:, sorted_idx]
    n_cells, n_win = Xs.shape

    windows = []
    window_expr = []
    for chrom in pd.unique(gene_chroms):
        idx_chr = np.where(gene_chroms == chrom)[0]
        step = max(1, window_size // 2)
        for i in range(0, len(idx_chr), step):
            block = idx_chr[i:i+window_size]
            if len(block) < min_genes_per_window:
                continue
            windows.append({'chrom': chrom, 'genes': block})
            window_expr.append(Xs[:, block].mean(axis=1))
    W = np.stack(window_expr, axis=1)

    chroms = sorted({w['chrom'] for w in windows}, key=chr_key)
    calls_chr = pd.DataFrame(0, index=adata.obs_names, columns=chroms, dtype=int)

    for cl in adata.obs[cluster_key].astype(str).unique():
        refs = cluster_refs.get(cl, [])
        if len(refs) < min_genes_per_window:
            continue
        mask_cl = (adata.obs[cluster_key].astype(str) == cl).values
        idx_cl = np.where(mask_cl)[0]
        mask_ref = adata.obs_names.isin(refs)
        idx_ref = np.where(mask_ref)[0]
        if len(idx_ref) == 0:
            continue
        ref_med = np.median(W[idx_ref, :], axis=0)
        ref_med = np.clip(ref_med, 1e-6, None)
        L = np.log2((W[idx_cl, :] + 1e-6) / ref_med[np.newaxis, :])
        if smoothing_sigma > 0:
            for chrom in chroms:
                win_idxs = [i for i,w in enumerate(windows) if w['chrom']==chrom]
                if len(win_idxs) > 1:
                    L[:, win_idxs] = gaussian_filter1d(
                        L[:, win_idxs],
                        sigma=smoothing_sigma,
                        axis=1,
                        mode='reflect'
                    )
        for chrom in chroms:
            win_idxs = [i for i,w in enumerate(windows) if w['chrom']==chrom]
            sub = L[:, win_idxs]
            frac_gain = (sub > lfc_threshold).sum(axis=1) / len(win_idxs)
            frac_loss = (sub < -lfc_threshold).sum(axis=1) / len(win_idxs)
            cells = adata.obs_names[idx_cl]
            calls_chr.loc[cells[frac_gain >= fraction_threshold], chrom] = +1
            calls_chr.loc[cells[frac_loss >= fraction_threshold], chrom] = -1

    return calls_chr, windows, var

def extract_cna_segments(
    calls_chr: pd.DataFrame,
    windows: list[dict],
    var: pd.DataFrame
) -> pd.DataFrame:
    """
    Flatten per‐cell per‐window calls into a list of segments.
    Parameters
    ----------
    calls_chr : DataFrame
        index = cell barcodes, columns = chromosomes, values in {-1,0,1}
    windows : list of dict
        each dict has keys 'chrom' and 'genes' = array of sorted var indices
    var : DataFrame
        the same .var you used when building windows, with .loc[first,'start'] and .loc[last,'end']
    Returns
    -------
    segs : DataFrame with columns
        ['cell', 'chromosome', 'start', 'end', 'genotype']
    """
    records = []

    win_meta = []
    for w in windows:
        chrom = w['chrom']
        gene_inds = w['genes']
        gene_names = var.index[gene_inds]
        st = var.loc[gene_names, 'start'].min()
        en = var.loc[gene_names, 'end'].max()
        win_meta.append((chrom, st, en))

    for cell in calls_chr.index:

        for win_i, (chrom, st, en) in enumerate(win_meta):
            call = calls_chr.at[cell, chrom]
            if call == 0:
                continue
            records.append({
                'cell':       cell,
                'chromosome': chrom,
                'start':      st,
                'end':        en,
                'genotype':   'gain' if call==1 else 'loss'
            })

    return pd.DataFrame(records)

def compute_mean_f1(calls_chr, adata):
    """
    calls_chr : pd.DataFrame, index=cells, cols=chromosomes, values in {-1,0,+1}
    adata.obs['simulated_cnvs']: either simple 'gain'/'none' or full "chr:start-end (CN #)" strings.
    """
    sim = adata.obs['simulated_cnvs'].astype(str).fillna('')
    uniques = set(sim.unique())

    if uniques <= {'gain','none'}:
        y_true = (sim == 'gain').astype(int).values

        y_pred = (calls_chr.values == 1).any(axis=1).astype(int)
        prec, rec, f1, _ = precision_recall_fscore_support(
            y_true, y_pred,
            average='binary', zero_division=0
        )
        return float(f1)

    ev = []
    for s in sim.values:
        for part in s.split(','):
            m = re.match(r'(\w+):\d+-\d+\s+\(CN\s+(\d+)\)', part.strip())
            if not m:
                continue
            chrom, cn = m.group(1), int(m.group(2))
            sign = +1 if cn > 2 else (-1 if cn < 2 else 0)
            if sign != 0:
                ev.append((chrom, sign))
    ev = list(set(ev))
    if not ev:
        raise ValueError("No CNV events parsed from 'simulated_cnvs'")

    ys, ps = [], []
    for chrom, sign in ev:
        y = sim.str.contains(rf'\b{chrom}:').astype(int).values
        p = (calls_chr[chrom].values == sign).astype(int)
        ys.append(y)
        ps.append(p)

    y_true = np.concatenate(ys)
    y_pred = np.concatenate(ps)
    _, _, f1, _ = precision_recall_fscore_support(
        y_true, y_pred,
        average='binary', zero_division=0
    )
    return float(f1)